{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/transformers.git\n!pip install git+https://github.com/huggingface/accelerate.git\n!pip install bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-09-11T16:18:04.312292Z","iopub.execute_input":"2024-09-11T16:18:04.313077Z","iopub.status.idle":"2024-09-11T16:19:45.777665Z","shell.execute_reply.started":"2024-09-11T16:18:04.313036Z","shell.execute_reply":"2024-09-11T16:19:45.776478Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/transformers.git\n  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-_76zqqmt\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-_76zqqmt\n  Resolved https://github.com/huggingface/transformers.git to commit ecf7024bde0d090ddf45120242a9469cfae87e51\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (0.4.4)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.45.0.dev0) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (2024.7.4)\nBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers: filename=transformers-4.45.0.dev0-py3-none-any.whl size=9706608 sha256=5657997bfc3543ae157c33942d7c0d95909a29429ae0fed60fc37b569131c3b3\n  Stored in directory: /tmp/pip-ephem-wheel-cache-nqscc5oi/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\nSuccessfully built transformers\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.0\n    Uninstalling transformers-4.44.0:\n      Successfully uninstalled transformers-4.44.0\nSuccessfully installed transformers-4.45.0.dev0\nCollecting git+https://github.com/huggingface/accelerate.git\n  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-yf7kkew6\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-yf7kkew6\n  Resolved https://github.com/huggingface/accelerate.git to commit d5b7b70e06f30f4cd821a98bb1542ea0c403a65d\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (2.4.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (0.24.6)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (0.4.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.35.0.dev0) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.35.0.dev0) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.35.0.dev0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.35.0.dev0) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.35.0.dev0) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.35.0.dev0) (1.3.0)\nBuilding wheels for collected packages: accelerate\n  Building wheel for accelerate (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for accelerate: filename=accelerate-0.35.0.dev0-py3-none-any.whl size=325554 sha256=a0937ab90fac561b7ec634f45e2c52bd55cb16606089fcf60acf4220d8dad07c\n  Stored in directory: /tmp/pip-ephem-wheel-cache-ieulnbuf/wheels/9c/a3/1e/47368f9b6575655fe9ee1b6350cfa7d4b0befe66a35f8a8365\nSuccessfully built accelerate\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.33.0\n    Uninstalling accelerate-0.33.0:\n      Successfully uninstalled accelerate-0.33.0\nSuccessfully installed accelerate-0.35.0.dev0\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom datasets import load_dataset\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.metrics import mean_squared_error, accuracy_score\nimport matplotlib.pyplot as plt\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T16:19:45.779794Z","iopub.execute_input":"2024-09-11T16:19:45.780121Z","iopub.status.idle":"2024-09-11T16:19:52.411818Z","shell.execute_reply.started":"2024-09-11T16:19:45.780088Z","shell.execute_reply":"2024-09-11T16:19:52.410848Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=\"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\")","metadata":{"execution":{"iopub.status.busy":"2024-09-11T16:20:15.382977Z","iopub.execute_input":"2024-09-11T16:20:15.383631Z","iopub.status.idle":"2024-09-11T16:20:15.494088Z","shell.execute_reply.started":"2024-09-11T16:20:15.383587Z","shell.execute_reply":"2024-09-11T16:20:15.493187Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    load_in_4bit=True,\n    device_map=\"auto\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T16:20:18.200935Z","iopub.execute_input":"2024-09-11T16:20:18.201794Z","iopub.status.idle":"2024-09-11T16:22:54.750002Z","shell.execute_reply.started":"2024-09-11T16:20:18.201750Z","shell.execute_reply":"2024-09-11T16:22:54.749012Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fccadcd5bc0747cc8736bda7f73d2d50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48803d3c0d984fc3a13f256ba599a39e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c262c0352efe4fb58e1e5f37d81a3b56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02fb982409374bfbb22485c3785f0cbd"}},"metadata":{}},{"name":"stderr","text":"The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"109a1d638502420ca47a32a16b465fd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"538b3a698e49412cb834bf3349afb9d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"121a031db398420ab2c611dc38933749"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a53928880bf24ff3bad56ef1e36b5f10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f9436cb4824483c8ab3c18bd85fcfd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e0e9a89cb3b43bda178aa4e0c8f7b06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"239f9c30233846bdada688f6c18e268b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"773a93eabcfd42019cb52b269a917d3a"}},"metadata":{}}]},{"cell_type":"code","source":"dataset = load_dataset(\"wiki_bio\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T17:10:20.082360Z","iopub.execute_input":"2024-09-11T17:10:20.083214Z","iopub.status.idle":"2024-09-11T17:10:20.087793Z","shell.execute_reply.started":"2024-09-11T17:10:20.083163Z","shell.execute_reply":"2024-09-11T17:10:20.086531Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"print(dataset['train'][0])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T16:38:44.509185Z","iopub.execute_input":"2024-09-11T16:38:44.509593Z","iopub.status.idle":"2024-09-11T16:38:44.515621Z","shell.execute_reply.started":"2024-09-11T16:38:44.509555Z","shell.execute_reply":"2024-09-11T16:38:44.514556Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"{'input_text': {'table': {'column_header': ['occupation', 'article_title', 'nationality', 'name', 'birth_date'], 'row_number': [1, 1, 1, 1, 1], 'content': ['aircraft designer and manufacturer', 'walter extra\\n', 'german', 'walter extra', '1954']}, 'context': 'walter extra\\n'}, 'target_text': 'walter extra is a german award-winning aerobatic pilot , chief aircraft designer and founder of extra flugzeugbau -lrb- extra aircraft construction -rrb- , a manufacturer of aerobatic aircraft .\\nextra was trained as a mechanical engineer .\\nhe began his flight training in gliders , transitioning to powered aircraft to perform aerobatics .\\nhe built and flew a pitts special aircraft and later built his own extra ea-230 .\\nextra began designing aircraft after competing in the 1982 world aerobatic championships .\\nhis aircraft constructions revolutionized the aerobatics flying scene and still dominate world competitions .\\nthe german pilot klaus schrodt won his world championship title flying an aircraft made by the extra firm .\\nwalter extra has designed a series of performance aircraft which include unlimited aerobatic aircraft and turboprop transports .\\n'}\n","output_type":"stream"}]},{"cell_type":"code","source":"def is_geographical(item):\n    geo_keywords = ['city', 'country', 'river', 'mountain', 'lake', 'ocean', 'island']\n    input_text = ' '.join(item['input_text']['table']['content']).lower()\n    return any(keyword in input_text for keyword in geo_keywords)\ngeo_data = dataset['train'].filter(is_geographical)\ndf = pd.DataFrame(geo_data)\ndf","metadata":{"execution":{"iopub.status.busy":"2024-09-11T16:40:08.123670Z","iopub.execute_input":"2024-09-11T16:40:08.124566Z","iopub.status.idle":"2024-09-11T16:41:04.128898Z","shell.execute_reply.started":"2024-09-11T16:40:08.124526Z","shell.execute_reply":"2024-09-11T16:41:04.127883Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/582659 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28faba8a7271470f9459f0713297789c"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                              input_text  \\\n0      {'table': {'column_header': ['clubs', 'height'...   \n1      {'table': {'column_header': ['clubs', 'height'...   \n2      {'table': {'column_header': ['finalyear', 'fin...   \n3      {'table': {'column_header': ['occupation', 'pr...   \n4      {'table': {'column_header': ['occupation', 'de...   \n...                                                  ...   \n53139  {'table': {'column_header': ['death_date', 'na...   \n53140  {'table': {'column_header': ['branch', 'party'...   \n53141  {'table': {'column_header': ['occupation', 'ge...   \n53142  {'table': {'column_header': ['genre', 'label',...   \n53143  {'table': {'column_header': ['clubs', 'height'...   \n\n                                             target_text  \n0      aaron hohlbein -lrb- born august 16 , 1985 in ...  \n1      joseph dorville `` joe '' walter -lrb- 16 augu...  \n2      craig harold paquette -lrb- ; born march 28 , ...  \n3      carlene m. walker is an american politician an...  \n4      vester pegg -lrb- may 23 , 1889 -- february 19...  \n...                                                  ...  \n53139  pierre jalbert -lrb- 9 january 1925 -- 22 janu...  \n53140  frank kell cahoon , sr. -lrb- june 20 , 1934 -...  \n53141  playaz circle is an american hip hop duo from ...  \n53142  valkyrie is a doom metal band from harrisonbur...  \n53143  rodolfo torres ruiz was a mexican footballer w...  \n\n[53144 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_text</th>\n      <th>target_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'table': {'column_header': ['clubs', 'height'...</td>\n      <td>aaron hohlbein -lrb- born august 16 , 1985 in ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'table': {'column_header': ['clubs', 'height'...</td>\n      <td>joseph dorville `` joe '' walter -lrb- 16 augu...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'table': {'column_header': ['finalyear', 'fin...</td>\n      <td>craig harold paquette -lrb- ; born march 28 , ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'table': {'column_header': ['occupation', 'pr...</td>\n      <td>carlene m. walker is an american politician an...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'table': {'column_header': ['occupation', 'de...</td>\n      <td>vester pegg -lrb- may 23 , 1889 -- february 19...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>53139</th>\n      <td>{'table': {'column_header': ['death_date', 'na...</td>\n      <td>pierre jalbert -lrb- 9 january 1925 -- 22 janu...</td>\n    </tr>\n    <tr>\n      <th>53140</th>\n      <td>{'table': {'column_header': ['branch', 'party'...</td>\n      <td>frank kell cahoon , sr. -lrb- june 20 , 1934 -...</td>\n    </tr>\n    <tr>\n      <th>53141</th>\n      <td>{'table': {'column_header': ['occupation', 'ge...</td>\n      <td>playaz circle is an american hip hop duo from ...</td>\n    </tr>\n    <tr>\n      <th>53142</th>\n      <td>{'table': {'column_header': ['genre', 'label',...</td>\n      <td>valkyrie is a doom metal band from harrisonbur...</td>\n    </tr>\n    <tr>\n      <th>53143</th>\n      <td>{'table': {'column_header': ['clubs', 'height'...</td>\n      <td>rodolfo torres ruiz was a mexican footballer w...</td>\n    </tr>\n  </tbody>\n</table>\n<p>53144 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def extract_text(input_text):\n    return ' '.join(input_text['table']['content'])\n\ndf['full_text'] = df['input_text'].apply(extract_text)\n\ndef extract_year(text):\n    years = [int(word) for word in text.split() if word.isdigit() and len(word) == 4]\n    return years[0] if years else np.nan\n\ndef extract_nationality(text):\n    nationalities = ['german', 'french', 'american', 'british', 'italian', 'spanish', 'chinese', 'japanese']\n    for nat in nationalities:\n        if nat in text.lower():\n            return nat\n    return 'other'\n\ndf['year'] = df['full_text'].apply(extract_year)\ndf['nationality'] = df['full_text'].apply(extract_nationality)\n\ndf = df.dropna()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T16:42:31.122621Z","iopub.execute_input":"2024-09-11T16:42:31.123596Z","iopub.status.idle":"2024-09-11T16:42:32.568658Z","shell.execute_reply.started":"2024-09-11T16:42:31.123556Z","shell.execute_reply":"2024-09-11T16:42:32.567590Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def generate_prompt(row):\n    content = row['input_text']['table']['content']\n    prompt = f\"Tell me about {content[0]}\"\n    return prompt\n\ndf['prompt'] = df.apply(generate_prompt, axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_embeddings(prompts, model, tokenizer, layer_num=-1):\n    embeddings = []\n    for prompt in prompts:\n        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(model.device)\n        with torch.no_grad():\n            outputs = model(**inputs, output_hidden_states=True)\n        embedding = outputs.hidden_states[layer_num][0, -1, :].cpu().numpy()\n        embeddings.append(embedding)\n    return np.array(embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T16:43:25.448600Z","iopub.execute_input":"2024-09-11T16:43:25.449430Z","iopub.status.idle":"2024-09-11T16:43:25.455659Z","shell.execute_reply.started":"2024-09-11T16:43:25.449390Z","shell.execute_reply":"2024-09-11T16:43:25.454721Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"first_layer_embeddings = get_embeddings(df['prompt'].tolist(), model, tokenizer, layer_num=1)\nmid_layer_embeddings = get_embeddings(df['prompt'].tolist(), model, tokenizer, layer_num=len(model.config.num_hidden_layers) // 2)\nfinal_layer_embeddings = get_embeddings(df['prompt'].tolist(), model, tokenizer, layer_num=-1)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T16:43:35.334879Z","iopub.execute_input":"2024-09-11T16:43:35.335262Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:435: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n  warnings.warn(\nStarting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(first_layer_embeddings.shape)\nprint(mid_layer_embeddings.shape)\nprint(final_layer_embeddings.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_reg = final_layer_embeddings\ny_reg = df['year'].values\n\nX_cls = final_layer_embeddings\ny_cls = df['nationality'].values\nX_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\nX_cls_train, X_cls_test, y_cls_train, y_cls_test = train_test_split(X_cls, y_cls, test_size=0.2, random_state=42)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg_model = LinearRegression()\nreg_model.fit(X_reg_train, y_reg_train)\ny_reg_pred = reg_model.predict(X_reg_test)\nreg_mse = mean_squared_error(y_reg_test, y_reg_pred)\nreg_r2 = reg_model.score(X_reg_test, y_reg_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Regression MSE: {reg_mse}\")\nprint(f\"Regression R-squared: {reg_r2}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cls_model = LogisticRegression(multi_class='ovr', max_iter=1000)\ncls_model.fit(X_cls_train, y_cls_train)\ny_cls_pred = cls_model.predict(X_cls_test)\ncls_accuracy = accuracy_score(y_cls_test, y_cls_pred)\nprint(f\"Classification Accuracy: {cls_accuracy}\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_names = ['First Layer', 'Mid Layer', 'Final Layer']\nlayer_embeddings = [first_layer_embeddings, mid_layer_embeddings, final_layer_embeddings]\n\nreg_scores = []\ncls_scores = []\n\nfor embeddings in layer_embeddings:\n\n    X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(embeddings, y_reg, test_size=0.2, random_state=42)\n    reg_model = LinearRegression()\n    reg_model.fit(X_reg_train, y_reg_train)\n    reg_scores.append(reg_model.score(X_reg_test, y_reg_test))\n\n    X_cls_train, X_cls_test, y_cls_train, y_cls_test = train_test_split(embeddings, y_cls, test_size=0.2, random_state=42)\n    cls_model = LogisticRegression(multi_class='ovr', max_iter=1000)\n    cls_model.fit(X_cls_train, y_cls_train)\n    cls_scores.append(accuracy_score(y_cls_test, cls_model.predict(X_cls_test)))\n\nplt.figure(figsize=(10, 6))\nplt.plot(layer_names, reg_scores, label='Regression R-squared', marker='o')\nplt.plot(layer_names, cls_scores, label='Classification Accuracy', marker='o')\nplt.xlabel('Layer')\nplt.ylabel('Score')\nplt.title('Performance Across Layers')\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}